{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = 19570101  # start date\n",
    "end_date = 20201231  # end date\n",
    "ch_data_path = \"./dataset/GKX_20201231.csv\" # characteristic data path\n",
    "mp_data_path = \"./dataset/PredictorData2023Monthly.csv\" # macro predictors data path\n",
    "full_clean_data_path = \"./dataset/full_dataset.csv\" # clean data path\n",
    "top_clean_data_path = \"./dataset/top_dataset.csv\" # clean data path\n",
    "bottom_clean_data_path = \"./dataset/bottom_dataset.csv\" # clean data path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load characteristic data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_data = pd.read_csv(ch_data_path)\n",
    "\n",
    "# select data according to date and format date\n",
    "ch_data = ch_data.loc[(ch_data['DATE'] >= start_date) & (ch_data['DATE'] <= end_date)].reset_index(drop=True)\n",
    "ch_data['DATE'] = pd.to_datetime(ch_data['DATE'], format='%Y%m%d') + pd.offsets.MonthEnd(0) # for filling null data\n",
    "\n",
    "# extract characteristic\n",
    "exclude_columns = ['permno', 'DATE', 'sic2', 'RET', 'prc','SHROUT','mve0']\n",
    "characteristics = ch_data.columns.difference(exclude_columns).tolist()\n",
    "\n",
    "# fill missing characteristic\n",
    "for ch in characteristics:\n",
    "    ch_data[ch] = ch_data.groupby('DATE')[ch].transform(lambda x: x.fillna(x.median()))\n",
    "for ch in characteristics:\n",
    "    ch_data[ch] = ch_data[ch].fillna(0)\n",
    "\n",
    "# drop unused columns\n",
    "ch_data.drop(['sic2', 'permno', 'prc','SHROUT','mve0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load macroeconomic predictors data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_data = pd.read_csv(mp_data_path)\n",
    "\n",
    "# select data according to date and format date\n",
    "mp_data = mp_data[(mp_data['yyyymm']>=start_date/100)&(mp_data['yyyymm']<=end_date//100)].reset_index(drop=True)\n",
    "mp_data['DATE'] = pd.to_datetime(mp_data['yyyymm'], format='%Y%m')  + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# calculate additional variables based on mp_data\n",
    "mp_data['Index'] = mp_data['Index'].str.replace(',','').astype('float')\n",
    "mp_data['d/p'] = mp_data['D12']/mp_data['Index']\n",
    "mp_data['e/p'] = mp_data['E12']/mp_data['Index']\n",
    "mp_data['tms'] = mp_data['lty'] - mp_data['tbl']\n",
    "mp_data['dfy'] = mp_data['BAA'] - mp_data['AAA']\n",
    "\n",
    "# drop unused columns\n",
    "mp_data.drop(['Index', 'D12', 'E12', 'AAA', 'yyyymm','BAA', 'lty', 'Rfree', 'infl', 'ltr', 'corpr', 'csp', 'CRSP_SPvw', 'CRSP_SPvwx',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ch and mp data\n",
    "data = pd.merge(ch_data, mp_data, how='left', on='DATE').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# construct covariates\n",
    "# ch_data.drop(['DATE'], axis=1, inplace=True)\n",
    "# mp_data.drop(['DATE'], axis=1, inplace=True)\n",
    "# chs = list(set(ch_data.columns))\n",
    "# mps = list(set(mp_data.columns))\n",
    "# covariates = pd.DataFrame()\n",
    "# for ch in chs:\n",
    "#     for mp in mps:\n",
    "#         covariates[ch+'*'+mp] = ch_data[ch] * mp_data[mp]\n",
    "# data = pd.concat([data, covariates], axis=1)\n",
    "\n",
    "# for gc\n",
    "del ([ch_data, mp_data])\n",
    "\n",
    "# store data\n",
    "data.to_csv(full_clean_data_path, index=None)\n",
    "\n",
    "data_top = data.sort_values('mvel1',ascending=False).groupby('DATE').head(1000).reset_index(drop=True) # top 1000\n",
    "data_top.to_csv(top_clean_data_path, index=None)\n",
    "del data_top\n",
    "\n",
    "data_bot = data.sort_values('mvel1',ascending=False).groupby('DATE').tail(1000).reset_index(drop=True) # bottom 1000\n",
    "data_bot.to_csv(bottom_clean_data_path, index=None)\n",
    "del data_bot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
